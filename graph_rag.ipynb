{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! pip install langchain langchain-community langchain-huggingface langgraph\n",
    "! pip install networkx python-dotenv\n",
    "! pip install ragas datasets matplotlib numpy\n",
    "! pip install pypdf sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import re\n",
    "import dotenv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from typing import List, Dict, Any, TypedDict, Annotated, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Anthropic via LangChain\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# RAGAS\n",
    "from transformers import logging as hf_logging\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPEN_API_URL\", \"https://inference.do-ai.run/v1\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\", \"true\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\", \"rag-sael\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\n",
    "    model=os.getenv(\"OPEN_MODEL\", \"openai-gpt-oss-120b\"),\n",
    "    model_provider=\"openai\",\n",
    "    base_url=os.getenv(\"OPEN_API_URL\", \"https://inference.do-ai.run/v1\"),\n",
    ")\n",
    "\n",
    "llm_extractor = init_chat_model(\n",
    "    model=os.getenv(\"OPEN_MODEL\", \"openai-gpt-oss-120b\"),\n",
    "    model_provider=\"openai\",\n",
    "    base_url=os.getenv(\"OPEN_API_URL\", \"https://inference.do-ai.run/v1\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EntityNode:\n",
    "    \"\"\"Representa uma entidade no grafo de conhecimento.\"\"\"\n",
    "    id: str\n",
    "    name: str\n",
    "    type: str            # Person, Organization, Concept, Location, Event\n",
    "    description: str = \"\"\n",
    "    chunk_ids: List[str] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class RelationEdge:\n",
    "    \"\"\"Representa uma rela√ß√£o entre duas entidades.\"\"\"\n",
    "    source_id: str\n",
    "    target_id: str\n",
    "    relation_type: str   # RELATES_TO, IS_A, PART_OF, CAUSES, etc.\n",
    "    description: str = \"\"\n",
    "    weight: float = 1.0\n",
    "\n",
    "\n",
    "class KnowledgeGraph:\n",
    "    \"\"\"Grafo de conhecimento baseado em NetworkX com busca por entidade e subgrafo.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.entities: Dict[str, EntityNode] = {}\n",
    "        self._name_index: Dict[str, str] = {}   # name.lower() ‚Üí entity_id\n",
    "\n",
    "    # ‚îÄ‚îÄ Inser√ß√£o ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    def add_entity(self, entity: EntityNode) -> None:\n",
    "        self.entities[entity.id] = entity\n",
    "        self._name_index[entity.name.lower()] = entity.id\n",
    "        self.graph.add_node(\n",
    "            entity.id,\n",
    "            name=entity.name,\n",
    "            type=entity.type,\n",
    "            description=entity.description,\n",
    "        )\n",
    "\n",
    "    def add_relation(self, relation: RelationEdge) -> None:\n",
    "        if relation.source_id in self.entities and relation.target_id in self.entities:\n",
    "            self.graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relation=relation.relation_type,\n",
    "                description=relation.description,\n",
    "                weight=relation.weight,\n",
    "            )\n",
    "\n",
    "    # ‚îÄ‚îÄ Busca ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "    def find_entity_by_name(self, name: str) -> Optional[EntityNode]:\n",
    "        \"\"\"Busca entidade por nome (case-insensitive, correspond√™ncia parcial).\"\"\"\n",
    "        name_lower = name.lower()\n",
    "        # Correspond√™ncia exata\n",
    "        if name_lower in self._name_index:\n",
    "            return self.entities[self._name_index[name_lower]]\n",
    "        # Correspond√™ncia parcial\n",
    "        for stored_name, eid in self._name_index.items():\n",
    "            if name_lower in stored_name or stored_name in name_lower:\n",
    "                return self.entities[eid]\n",
    "        return None\n",
    "\n",
    "    def get_neighbors(self, entity_id: str, depth: int = 2) -> List[str]:\n",
    "        \"\"\"Retorna IDs de vizinhos at√© profundidade N via BFS.\"\"\"\n",
    "        visited = set()\n",
    "        frontier = {entity_id}\n",
    "        for _ in range(depth):\n",
    "            next_frontier = set()\n",
    "            for nid in frontier:\n",
    "                nbrs = set(self.graph.successors(nid)) | set(self.graph.predecessors(nid))\n",
    "                next_frontier.update(nbrs - visited)\n",
    "            visited.update(frontier)\n",
    "            frontier = next_frontier\n",
    "        visited.update(frontier)\n",
    "        return list(visited)\n",
    "\n",
    "    def build_context(self, node_ids: List[str]) -> str:\n",
    "        \"\"\"Converte subgrafo em texto estruturado para o LLM.\"\"\"\n",
    "        if not node_ids:\n",
    "            return \"Nenhuma entidade relevante encontrada no grafo.\"\n",
    "\n",
    "        subgraph = self.graph.subgraph(node_ids)\n",
    "        lines = [\"### Entidades Relevantes do Grafo\\n\"]\n",
    "\n",
    "        for nid in subgraph.nodes():\n",
    "            entity = self.entities.get(nid)\n",
    "            if entity:\n",
    "                lines.append(f\"- **{entity.name}** [{entity.type}]: {entity.description}\")\n",
    "\n",
    "        lines.append(\"\\n### Rela√ß√µes\\n\")\n",
    "        for u, v, data in subgraph.edges(data=True):\n",
    "            u_name = self.entities.get(u, EntityNode(u, u, \"\")).name\n",
    "            v_name = self.entities.get(v, EntityNode(v, v, \"\")).name\n",
    "            rel = data.get(\"relation\", \"RELATES_TO\")\n",
    "            desc = data.get(\"description\", \"\")\n",
    "            lines.append(f\"- {u_name} --[{rel}]--> {v_name}: {desc}\")\n",
    "\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    @property\n",
    "    def stats(self) -> Dict[str, int]:\n",
    "        return {\n",
    "            \"nodes\": self.graph.number_of_nodes(),\n",
    "            \"edges\": self.graph.number_of_edges(),\n",
    "        }\n",
    "\n",
    "knowledge_graph = KnowledgeGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\n",
    "    path=\"docs\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"‚úÖ {len(docs)} p√°ginas carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "for i, split in enumerate(all_splits):\n",
    "    split.metadata[\"chunk_id\"] = f\"chunk_{i}\"\n",
    "\n",
    "# Indexa no vector store (mesmo do agent_rag)\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(f\"‚úÖ {len(all_splits)} chunks criados e indexados no vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_SYSTEM = \"\"\"Voc√™ √© um extrator especializado de entidades e rela√ß√µes.\n",
    "Retorne APENAS um JSON v√°lido, sem texto adicional, sem markdown.\"\"\"\n",
    "\n",
    "EXTRACTION_TEMPLATE = \"\"\"Analise o texto e extraia entidades e rela√ß√µes.\n",
    "\n",
    "Retorne SOMENTE este JSON (sem blocos de c√≥digo, sem explica√ß√µes):\n",
    "{{\n",
    "  \"entities\": [\n",
    "    {{\"id\": \"e1\", \"name\": \"Nome da Entidade\", \"type\": \"Concept|Person|Organization|Location|Event\", \"description\": \"descri√ß√£o breve\"}}\n",
    "  ],\n",
    "  \"relations\": [\n",
    "    {{\"source\": \"e1\", \"target\": \"e2\", \"type\": \"RELATES_TO|IS_A|PART_OF|CAUSES|DEFINES\", \"description\": \"como se relacionam\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Texto:\n",
    "{text}\"\"\"\n",
    "\n",
    "\n",
    "def extract_entities_from_chunk(chunk: Document) -> Dict:\n",
    "    \"\"\"Chama Claude para extrair entidades e rela√ß√µes de um chunk.\"\"\"\n",
    "    prompt = EXTRACTION_TEMPLATE.format(text=chunk.page_content[:1500])\n",
    "    messages = [\n",
    "        SystemMessage(content=EXTRACTION_SYSTEM),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "    response = llm_extractor.invoke(messages)\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # Remove blocos de c√≥digo se o modelo incluir por engano\n",
    "    raw = re.sub(r\"```(?:json)?\\s*\", \"\", raw).strip().rstrip(\"`\")\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"entities\": [], \"relations\": []}\n",
    "\n",
    "\n",
    "def ingest_chunk_into_graph(chunk: Document, extraction: Dict) -> None:\n",
    "    \"\"\"Adiciona entidades e rela√ß√µes extra√≠das ao grafo de conhecimento.\"\"\"\n",
    "    chunk_id = chunk.metadata.get(\"chunk_id\", str(uuid.uuid4()))\n",
    "    local_id_map: Dict[str, str] = {}  # id local do JSON ‚Üí id global no grafo\n",
    "\n",
    "    # Adiciona entidades\n",
    "    for ent in extraction.get(\"entities\", []):\n",
    "        global_id = f\"{ent['name'].lower().replace(' ', '_')}_{ent['type'].lower()}\"\n",
    "        local_id_map[ent[\"id\"]] = global_id\n",
    "\n",
    "        if global_id not in knowledge_graph.entities:\n",
    "            knowledge_graph.add_entity(EntityNode(\n",
    "                id=global_id,\n",
    "                name=ent[\"name\"],\n",
    "                type=ent.get(\"type\", \"Concept\"),\n",
    "                description=ent.get(\"description\", \"\"),\n",
    "                chunk_ids=[chunk_id],\n",
    "            ))\n",
    "        else:\n",
    "            # Entidade j√° existe ‚Äî apenas registra o chunk\n",
    "            knowledge_graph.entities[global_id].chunk_ids.append(chunk_id)\n",
    "\n",
    "    for rel in extraction.get(\"relations\", []):\n",
    "        src = local_id_map.get(rel[\"source\"])\n",
    "        tgt = local_id_map.get(rel[\"target\"])\n",
    "        if src and tgt:\n",
    "            knowledge_graph.add_relation(RelationEdge(\n",
    "                source_id=src,\n",
    "                target_id=tgt,\n",
    "                relation_type=rel.get(\"type\", \"RELATES_TO\"),\n",
    "                description=rel.get(\"description\", \"\"),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHUNKS_TO_EXTRACT = min(len(all_splits), 20)\n",
    "\n",
    "for i, chunk in enumerate(all_splits[:MAX_CHUNKS_TO_EXTRACT]):\n",
    "    print(f\"  [{i+1}/{MAX_CHUNKS_TO_EXTRACT}] Chunk {chunk.metadata.get('chunk_id')}...\", end=\" \")\n",
    "    extraction = extract_entities_from_chunk(chunk)\n",
    "    ingest_chunk_into_graph(chunk, extraction)\n",
    "    n_ents = len(extraction.get(\"entities\", []))\n",
    "    n_rels = len(extraction.get(\"relations\", []))\n",
    "    print(f\"{n_ents} entidades, {n_rels} rela√ß√µes\")\n",
    "\n",
    "stats = knowledge_graph.stats\n",
    "print(f\"\\nGrafo constru√≠do: {stats['nodes']} n√≥s | {stats['edges']} arestas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_vector_context(query: str):\n",
    "    \"\"\"Recupera chunks de texto relevantes por similaridade sem√¢ntica.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        f\"Source: {doc.metadata}\\nContent: {doc.page_content}\"\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_graph_context(query: str):\n",
    "    \"\"\"Recupera contexto estruturado do grafo de conhecimento: entidades e rela√ß√µes relevantes √† query.\"\"\"\n",
    "    # Identifica palavras-chave na query para entity linking\n",
    "    words = [w.strip('.,;:?!\"') for w in query.split() if len(w) > 3]\n",
    "\n",
    "    relevant_nodes: List[str] = []\n",
    "    for word in words:\n",
    "        entity = knowledge_graph.find_entity_by_name(word)\n",
    "        if entity:\n",
    "            neighbors = knowledge_graph.get_neighbors(entity.id, depth=2)\n",
    "            relevant_nodes.extend(neighbors)\n",
    "\n",
    "    # Deduplica e limita\n",
    "    relevant_nodes = list(set(relevant_nodes))[:40]\n",
    "\n",
    "    graph_context = knowledge_graph.build_context(relevant_nodes)\n",
    "    return graph_context, relevant_nodes\n",
    "\n",
    "\n",
    "tools = [retrieve_vector_context, retrieve_graph_context]\n",
    "print(\"Tools registrados:\", [t.name for t in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRAGState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"Voc√™ √© um assistente especializado em an√°lise de documentos com acesso a um grafo de conhecimento.\n",
    "\n",
    "Voc√™ possui DOIS tools:\n",
    "1. retrieve_graph_context ‚Äî recupera entidades e rela√ß√µes estruturadas do grafo de conhecimento\n",
    "2. retrieve_vector_context ‚Äî recupera trechos de texto por similaridade sem√¢ntica\n",
    "\n",
    "Para responder bem:\n",
    "- Sempre use retrieve_graph_context primeiro para entender as rela√ß√µes entre conceitos\n",
    "- Use retrieve_vector_context para obter detalhes textuais complementares\n",
    "- Integre ambas as fontes na sua resposta\n",
    "- Cite explicitamente quais entidades e rela√ß√µes do grafo embasam sua resposta\n",
    "- Responda sempre em portugu√™s, mesmo que a pergunta seja em outro idioma\"\"\"\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def agent_node(state: GraphRAGState) -> GraphRAGState:\n",
    "    \"\"\"N√≥ do agente: Claude decide a pr√≥xima a√ß√£o.\"\"\"\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state: GraphRAGState) -> str:\n",
    "    \"\"\"Roteamento: continua para tools ou encerra.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(GraphRAGState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "agent = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"Agente LangGraph compilado\")\n",
    "print(\"   Fluxo: agent ‚Üí [tools ‚Üí agent]* ‚Üí END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_graph_rag(question: str, thread_id: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Executa uma query no agente Graph RAG e retorna a resposta com metadados.\"\"\"\n",
    "    if thread_id is None:\n",
    "        thread_id = str(uuid.uuid4())\n",
    "\n",
    "    events = list(agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}},\n",
    "        stream_mode=\"values\",\n",
    "    ))\n",
    "\n",
    "    final_event = events[-1]\n",
    "    answer = final_event[\"messages\"][-1].content\n",
    "\n",
    "    # Coleta contextos para avalia√ß√£o RAGAS\n",
    "    retrieved_docs = vector_store.similarity_search(question, k=3)\n",
    "    contexts = [doc.page_content for doc in retrieved_docs]\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"contexts\": contexts,\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "\n",
    "test_question = \"O que √© l√≥gica proposicional?\"\n",
    "print(f\"Pergunta: {test_question}\\n\")\n",
    "\n",
    "result = query_graph_rag(test_question)\n",
    "print(\"Resposta do Graph RAG:\")\n",
    "print(\"-\" * 60)\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"O que √© l√≥gica proposicional segundo a apostila?\",\n",
    "    \"Como a apostila define uma proposi√ß√£o?\",\n",
    "    \"O que s√£o conectivos l√≥gicos e quais s√£o apresentados no material?\",\n",
    "    \"O que √© uma tabela-verdade e para que ela √© utilizada?\",\n",
    "    \"Como a apostila define tautologia, contradi√ß√£o e conting√™ncia?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"L√≥gica proposicional √© o ramo da l√≥gica que estuda proposi√ß√µes e as rela√ß√µes entre elas por meio de conectivos l√≥gicos.\",\n",
    "    \"Proposi√ß√£o √© toda senten√ßa declarativa que pode ser classificada como verdadeira ou falsa, mas n√£o ambas.\",\n",
    "    \"Conectivos l√≥gicos s√£o operadores que conectam proposi√ß√µes, como nega√ß√£o (¬¨), conjun√ß√£o (‚àß), disjun√ß√£o (‚à®), condicional (‚Üí) e bicondicional (‚Üî).\",\n",
    "    \"Tabela-verdade √© um m√©todo utilizado para determinar o valor l√≥gico de proposi√ß√µes compostas a partir dos valores l√≥gicos das proposi√ß√µes simples.\",\n",
    "    \"Tautologia √© uma proposi√ß√£o composta que √© sempre verdadeira; contradi√ß√£o √© sempre falsa; conting√™ncia √© aquela que pode ser verdadeira ou falsa dependendo dos valores das proposi√ß√µes componentes.\"\n",
    "]\n",
    "\n",
    "print(f\"{len(test_queries)} queries de avalia√ß√£o configuradas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_rag_evaluation() -> Any:\n",
    "    \"\"\"Executa o agente Graph RAG nas queries de teste e avalia com RAGAS.\"\"\"\n",
    "    print(\"Executando Graph RAG agent para coletar dados de teste...\\n\")\n",
    "    ragas_data = []\n",
    "\n",
    "    for i, query in enumerate(test_queries):\n",
    "        print(f\"  [{i+1}/{len(test_queries)}] {query}\")\n",
    "        result = query_graph_rag(query)\n",
    "        ragas_data.append({\n",
    "            \"question\": result[\"question\"],\n",
    "            \"contexts\": result[\"contexts\"],\n",
    "            \"answer\": result[\"answer\"],\n",
    "            \"ground_truth\": ground_truths[i],\n",
    "        })\n",
    "\n",
    "    test_dataset = Dataset.from_list(ragas_data)\n",
    "\n",
    "    print(\"\\nExecutando avalia√ß√£o RAGAS...\")\n",
    "\n",
    "    eval_llm = init_chat_model(\n",
    "        model=os.getenv(\"OPEN_MODEL\", \"openai-gpt-oss-120b\"),\n",
    "        model_provider=\"openai\",\n",
    "        base_url=os.getenv(\"OPEN_API_URL\", \"https://inference.do-ai.run/v1\"),\n",
    "    )\n",
    "\n",
    "    result = evaluate(\n",
    "        test_dataset,\n",
    "        metrics=[faithfulness, answer_relevancy, context_precision, context_recall],\n",
    "        llm=eval_llm,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== RESULTADOS RAGAS ‚Äî Graph RAG com Claude ===\")\n",
    "    print(result)\n",
    "\n",
    "    df = result.to_pandas()\n",
    "    print(\"\\nDetalhes por query:\")\n",
    "    print(df.to_string())\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "ragas_result = run_graph_rag_evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = ragas_result.to_pandas()\n",
    "\n",
    "metrics = [\"faithfulness\", \"answer_relevancy\", \"context_precision\", \"context_recall\"]\n",
    "metric_labels = [\"Faithfulness\", \"Answer Relevancy\", \"Context Precision\", \"Context Recall\"]\n",
    "available_metrics = [m for m in metrics if m in df_results.columns]\n",
    "available_labels  = [metric_labels[i] for i, m in enumerate(metrics) if m in df_results.columns]\n",
    "\n",
    "if not available_metrics:\n",
    "    raise ValueError(\"Nenhuma m√©trica esperada encontrada em df_results.\")\n",
    "\n",
    "plot_df = df_results[available_metrics].apply(lambda col: col.astype(float)).copy()\n",
    "mean_scores = plot_df.mean().tolist()\n",
    "n_queries   = len(plot_df)\n",
    "colors      = [\"#2c3e50\", \"#3498db\", \"#e74c3c\", \"#27ae60\"][:len(available_metrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.size\": 11,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"figure.titlesize\": 14,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"lines.markersize\": 8,\n",
    "})\n",
    "\n",
    "fig = plt.figure(figsize=(12, 42))\n",
    "fig.suptitle(\"Avalia√ß√£o de M√©tricas RAGAS ‚Äî Graph RAG com Claude Sonnet 4.6\",\n",
    "             fontsize=16, fontweight=\"bold\", y=0.995)\n",
    "\n",
    "x = np.arange(n_queries)\n",
    "\n",
    "# (a) M√©tricas M√©dias\n",
    "ax1 = fig.add_subplot(7, 1, 1)\n",
    "bars = ax1.bar(range(len(available_metrics)), mean_scores, color=colors,\n",
    "               edgecolor=\"black\", linewidth=1, width=0.5)\n",
    "ax1.set_title(\"(a) M√©tricas M√©dias\", fontweight=\"bold\", pad=12)\n",
    "ax1.set_ylabel(\"Score M√©dio\")\n",
    "ax1.set_ylim(0, 1.15)\n",
    "ax1.set_xticks(range(len(available_metrics)))\n",
    "ax1.set_xticklabels(available_labels)\n",
    "ax1.axhline(y=1.0, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax1.grid(axis=\"y\", linestyle=\":\", alpha=0.4)\n",
    "for bar, score in zip(bars, mean_scores):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, score + 0.03, f\"{score:.3f}\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "# (b) M√©tricas por Query\n",
    "ax2 = fig.add_subplot(7, 1, 2)\n",
    "width = 0.18\n",
    "for i, (metric, label) in enumerate(zip(available_metrics, available_labels)):\n",
    "    offset = width * i\n",
    "    rects = ax2.bar(x + offset, plot_df[metric].values, width, label=label,\n",
    "                    color=colors[i], edgecolor=\"black\", linewidth=0.6)\n",
    "    for rect, val in zip(rects, plot_df[metric].values):\n",
    "        ax2.text(rect.get_x() + rect.get_width()/2, rect.get_height() + 0.02,\n",
    "                 f\"{val:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9, fontweight=\"bold\")\n",
    "ax2.set_title(\"(b) M√©tricas por Query\", fontweight=\"bold\", pad=12)\n",
    "ax2.set_xlabel(\"Query\")\n",
    "ax2.set_ylabel(\"Score\")\n",
    "ax2.set_xticks(x + width * (len(available_metrics) - 1) / 2)\n",
    "ax2.set_xticklabels([f\"Q{i+1}\" for i in range(n_queries)])\n",
    "ax2.set_ylim(0, 1.25)\n",
    "ax2.axhline(y=1.0, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax2.legend(loc=\"upper right\", frameon=True, framealpha=0.95, fontsize=9, ncol=4)\n",
    "ax2.grid(axis=\"y\", linestyle=\":\", alpha=0.4)\n",
    "\n",
    "# (c) Radar\n",
    "ax3 = fig.add_subplot(7, 1, 3, projection=\"polar\")\n",
    "angles = np.linspace(0, 2 * np.pi, len(available_metrics), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "radar_values = mean_scores + [mean_scores[0]]\n",
    "ax3.plot(angles, radar_values, color=\"#2c3e50\", linewidth=2.5, marker=\"o\", markersize=10)\n",
    "ax3.fill(angles, radar_values, color=\"#3498db\", alpha=0.25)\n",
    "for angle, value, label in zip(angles[:-1], mean_scores, available_labels):\n",
    "    ax3.annotate(f\"{value:.3f}\", xy=(angle, value), xytext=(angle, value + 0.18),\n",
    "                 ha=\"center\", va=\"bottom\", fontsize=11, fontweight=\"bold\")\n",
    "ax3.set_xticks(angles[:-1])\n",
    "ax3.set_xticklabels(available_labels, fontsize=11)\n",
    "ax3.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax3.set_yticklabels([\"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"], fontsize=9, color=\"gray\")\n",
    "ax3.set_ylim(0, 1.15)\n",
    "ax3.set_title(\"(c) Radar de M√©tricas\", fontweight=\"bold\", pad=20, y=1.1)\n",
    "ax3.grid(True, linestyle=\":\", alpha=0.5)\n",
    "\n",
    "# (d) Heatmap\n",
    "ax4 = fig.add_subplot(7, 1, 4)\n",
    "heatmap_data = plot_df.values\n",
    "im = ax4.imshow(heatmap_data, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "ax4.set_title(\"(d) Heatmap de Scores\", fontweight=\"bold\", pad=12)\n",
    "ax4.set_xticks(np.arange(len(available_metrics)))\n",
    "ax4.set_xticklabels(available_labels)\n",
    "ax4.set_yticks(np.arange(n_queries))\n",
    "ax4.set_yticklabels([f\"Q{i+1}\" for i in range(n_queries)])\n",
    "for i in range(n_queries):\n",
    "    for j in range(len(available_metrics)):\n",
    "        val = heatmap_data[i, j]\n",
    "        text_color = \"white\" if val < 0.4 or val > 0.75 else \"black\"\n",
    "        ax4.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\",\n",
    "                 color=text_color, fontsize=12, fontweight=\"bold\")\n",
    "cbar = fig.colorbar(im, ax=ax4, fraction=0.03, pad=0.02)\n",
    "cbar.set_label(\"Score\", fontsize=11)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# (e) Boxplot\n",
    "ax5 = fig.add_subplot(7, 1, 5)\n",
    "box_data = [plot_df[m].dropna().values for m in available_metrics]\n",
    "bp = ax5.boxplot(box_data, labels=available_labels, patch_artist=True,\n",
    "                 showmeans=True, meanprops={\"marker\": \"D\", \"markerfacecolor\": \"red\", \"markersize\": 8})\n",
    "for patch, color in zip(bp[\"boxes\"], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "    patch.set_edgecolor(\"black\")\n",
    "    patch.set_linewidth(1)\n",
    "for i, data in enumerate(box_data):\n",
    "    mean_val   = np.mean(data)\n",
    "    median_val = np.median(data)\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    ax5.text(i + 1, q3 + 0.12, f\"Œº={mean_val:.2f}\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\", color=\"red\")\n",
    "    ax5.text(i + 1, q1 - 0.12, f\"M={median_val:.2f}\",\n",
    "             ha=\"center\", va=\"top\", fontsize=10, color=\"black\", fontweight=\"bold\")\n",
    "ax5.set_title(\"(e) Distribui√ß√£o de Scores\", fontweight=\"bold\", pad=12)\n",
    "ax5.set_ylabel(\"Score\")\n",
    "ax5.set_ylim(-0.3, 1.35)\n",
    "ax5.axhline(y=1.0, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax5.grid(axis=\"y\", linestyle=\":\", alpha=0.4)\n",
    "\n",
    "# (f) Evolu√ß√£o por Query\n",
    "ax6 = fig.add_subplot(7, 1, 6)\n",
    "markers = [\"o\", \"s\", \"^\", \"D\"]\n",
    "for i, (metric, label) in enumerate(zip(available_metrics, available_labels)):\n",
    "    ax6.plot(x, plot_df[metric], marker=markers[i], label=label,\n",
    "             color=colors[i], linewidth=2.5, markersize=10,\n",
    "             markeredgecolor=\"black\", markeredgewidth=0.8)\n",
    "    for xi, val in zip(x, plot_df[metric]):\n",
    "        ax6.annotate(f\"{val:.2f}\", xy=(xi, val), xytext=(0, 12),\n",
    "                     textcoords=\"offset points\", ha=\"center\", va=\"bottom\",\n",
    "                     fontsize=10, fontweight=\"bold\")\n",
    "ax6.set_title(\"(f) Evolu√ß√£o por Query\", fontweight=\"bold\", pad=12)\n",
    "ax6.set_xlabel(\"Query\")\n",
    "ax6.set_ylabel(\"Score\")\n",
    "ax6.set_xticks(x)\n",
    "ax6.set_xticklabels([f\"Q{i+1}\" for i in range(n_queries)])\n",
    "ax6.set_ylim(-0.05, 1.3)\n",
    "ax6.axhline(y=1.0, color=\"gray\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax6.legend(loc=\"lower right\", frameon=True, framealpha=0.95, fontsize=10, ncol=2)\n",
    "ax6.grid(linestyle=\":\", alpha=0.4)\n",
    "\n",
    "# (g) Resumo Estat√≠stico\n",
    "ax7 = fig.add_subplot(7, 1, 7)\n",
    "ax7.axis(\"off\")\n",
    "desc = plot_df.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]].round(3)\n",
    "table_data = [[\"M√©trica\", \"M√©dia (Œº)\", \"Desvio (œÉ)\", \"M√≠nimo\", \"M√°ximo\"]]\n",
    "for m, label in zip(available_metrics, available_labels):\n",
    "    table_data.append([\n",
    "        label,\n",
    "        f\"{desc.loc['mean', m]:.3f}\",\n",
    "        f\"{desc.loc['std', m]:.3f}\",\n",
    "        f\"{desc.loc['min', m]:.3f}\",\n",
    "        f\"{desc.loc['max', m]:.3f}\",\n",
    "    ])\n",
    "table = ax7.table(\n",
    "    cellText=table_data[1:],\n",
    "    colLabels=table_data[0],\n",
    "    loc=\"center\",\n",
    "    cellLoc=\"center\",\n",
    "    colColours=[\"#f0f0f0\"] * 5,\n",
    "    cellColours=[[\"white\"] * 5 for _ in range(len(available_metrics))],\n",
    ")\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 2)\n",
    "for i in range(5):\n",
    "    table[(0, i)].set_text_props(fontweight=\"bold\")\n",
    "    table[(0, i)].set_facecolor(\"#d0d0d0\")\n",
    "ax7.set_title(\"(g) Resumo Estat√≠stico\", fontweight=\"bold\", pad=12, y=0.95)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_knowledge_graph(max_nodes: int = 30) -> None:\n",
    "    \"\"\"Plota o grafo de conhecimento com layout spring e cores por tipo de entidade.\"\"\"\n",
    "    G = knowledge_graph.graph\n",
    "\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"Grafo vazio. Execute a ingest√£o primeiro.\")\n",
    "        return\n",
    "\n",
    "    # Limita para visualiza√ß√£o\n",
    "    nodes_to_show = list(G.nodes())[:max_nodes]\n",
    "    subG = G.subgraph(nodes_to_show)\n",
    "\n",
    "    type_colors = {\n",
    "        \"Concept\":      \"#3498db\",\n",
    "        \"Person\":       \"#e74c3c\",\n",
    "        \"Organization\": \"#27ae60\",\n",
    "        \"Location\":     \"#f39c12\",\n",
    "        \"Event\":        \"#9b59b6\",\n",
    "    }\n",
    "\n",
    "    node_colors = [\n",
    "        type_colors.get(\n",
    "            knowledge_graph.entities.get(n, EntityNode(n, n, \"Concept\")).type,\n",
    "            \"#95a5a6\"\n",
    "        )\n",
    "        for n in subG.nodes()\n",
    "    ]\n",
    "\n",
    "    node_labels = {\n",
    "        n: knowledge_graph.entities.get(n, EntityNode(n, n, \"\")).name\n",
    "        for n in subG.nodes()\n",
    "    }\n",
    "\n",
    "    edge_labels = {\n",
    "        (u, v): data.get(\"relation\", \"\")\n",
    "        for u, v, data in subG.edges(data=True)\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(subG, k=2.5, seed=42)\n",
    "\n",
    "    nx.draw_networkx_nodes(subG, pos, node_color=node_colors,\n",
    "                           node_size=800, alpha=0.9)\n",
    "    nx.draw_networkx_labels(subG, pos, labels=node_labels,\n",
    "                            font_size=8, font_weight=\"bold\")\n",
    "    nx.draw_networkx_edges(subG, pos, edge_color=\"#7f8c8d\",\n",
    "                           arrows=True, arrowsize=15,\n",
    "                           connectionstyle=\"arc3,rad=0.1\", alpha=0.7)\n",
    "    nx.draw_networkx_edge_labels(subG, pos, edge_labels=edge_labels,\n",
    "                                 font_size=7, font_color=\"#2c3e50\")\n",
    "\n",
    "    # Legenda\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(color=c, label=t)\n",
    "        for t, c in type_colors.items()\n",
    "    ]\n",
    "    plt.legend(handles=legend_patches, loc=\"upper left\",\n",
    "               frameon=True, fontsize=10)\n",
    "\n",
    "    plt.title(\n",
    "        f\"Grafo de Conhecimento ‚Äî {subG.number_of_nodes()} n√≥s | {subG.number_of_edges()} arestas\",\n",
    "        fontsize=14, fontweight=\"bold\", pad=15\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_knowledge_graph(max_nodes=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7b",
   "metadata": {},
   "source": [
    "## üìã 15. Resumo do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*65)\n",
    "print(\"  GRAPH RAG ‚Äî RESUMO DO PIPELINE\")\n",
    "print(\"=\"*65)\n",
    "print(f\"  Modelo:          Claude Sonnet 4.6\")\n",
    "print(f\"  Embeddings:      HuggingFace all-MiniLM-L6-v2\")\n",
    "print(f\"  Vector Store:    InMemoryVectorStore (LangChain)\")\n",
    "print(f\"  Orquestra√ß√£o:    LangGraph (StateGraph)\")\n",
    "print(f\"  Observabilidade: LangSmith (project: {os.environ['LANGCHAIN_PROJECT']})\")\n",
    "print(f\"  Grafo:           NetworkX DiGraph\")\n",
    "print(\"-\"*65)\n",
    "print(f\"  Documentos carregados:  {len(docs)}\")\n",
    "print(f\"  Chunks indexados:       {len(all_splits)}\")\n",
    "graph_stats = knowledge_graph.stats\n",
    "print(f\"  Entidades no grafo:     {graph_stats['nodes']}\")\n",
    "print(f\"  Rela√ß√µes no grafo:      {graph_stats['edges']}\")\n",
    "print(\"-\"*65)\n",
    "print(f\"  Tools do agente:\")\n",
    "for t in tools:\n",
    "    print(f\"    ‚Ä¢ {t.name}\")\n",
    "print(\"=\"*65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
